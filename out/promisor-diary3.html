<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="apple-touch-icon" sizes="180x180" href="https://i.imgur.com/2nHGFTv.png"/><link rel="icon" type="image/png" sizes="32x32" href="https://i.imgur.com/2nHGFTv.png"/><link rel="icon" type="image/png" sizes="16x16" href="https://i.imgur.com/2nHGFTv.png"/><link rel="manifest" href="/site.webmanifest"/><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#da532c"/><meta name="theme-color" content="#ffffff"/><title>Nginx 리버스 프록시 적용하여 Tomcat과 연동하기</title><meta name="title" content="Nginx 리버스 프록시 적용하여 Tomcat과 연동하기"/><meta name="description" content=""/><meta name="keywords" content=""/><meta name="robots" content="index, follow"/><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><meta name="language" content="Korean"/><meta name="author" content="Sanha Ko"/><meta property="og:title" content="Nginx 리버스 프록시 적용하여 Tomcat과 연동하기"/><meta property="og:url" content="https://headf1rst.github.io/TIL/promisor-diary3"/><meta property="og:type" content="blog"/><meta property="og:image" content="https://sysopszone.files.wordpress.com/2017/09/loadbalancer.jpeg?w=676"/><meta property="og:description"/><meta name="next-head-count" content="22"/><link rel="preload" href="/TIL/_next/static/css/754b961274c075df.css" as="style"/><link rel="stylesheet" href="/TIL/_next/static/css/754b961274c075df.css" data-n-g=""/><link rel="preload" href="/TIL/_next/static/css/38994dd0aed51f22.css" as="style"/><link rel="stylesheet" href="/TIL/_next/static/css/38994dd0aed51f22.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/TIL/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/TIL/_next/static/chunks/webpack-ac557983bcc4c022.js" defer=""></script><script src="/TIL/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/TIL/_next/static/chunks/main-dc8c1543918dad35.js" defer=""></script><script src="/TIL/_next/static/chunks/pages/_app-421e211a78340d83.js" defer=""></script><script src="/TIL/_next/static/chunks/202-7f08bae5ecc79443.js" defer=""></script><script src="/TIL/_next/static/chunks/pages/%5Bid%5D-e822cf87f2ef122d.js" defer=""></script><script src="/TIL/_next/static/DgHcyLVbQaP3fKIpTojx6/_buildManifest.js" defer=""></script><script src="/TIL/_next/static/DgHcyLVbQaP3fKIpTojx6/_ssgManifest.js" defer=""></script></head><body><div id="__next"><nav class="flex bg-white sticky top-0 left-0 z-50 justify-between items-center border-b-2 border-gray-100 py-3 md:justify-start md:space-x-10 px-10 sm:px-5 dark:bg-[#0d1117] dark:text-[#c9d1d9] dark:border-gray-600"><div class="flex justify-start"><a href="/TIL"><div class="flex items-center gap-2 cursor-pointer"><img src="https://i.imgur.com/2nHGFTv.png" width="40" height="40" alt="블로그 아이콘"/><h1 class="text-lg ">산하개발실록</h1></div></a></div><div class="flex justify-between gap-10 sm:hidden"><a href="/TIL"><button class="font-light hover:text-indigo-300 text-base">Home</button></a><a href="/TIL/category"><button class="font-light hover:text-indigo-300 text-base">Category</button></a><a href="https://plain-composer-c65.notion.site/29c7640fdf054059b6ea28ed61189bfb" target="_blank" rel="noreferrer" class="hover:text-indigo-300 text-base font-light flex gap-1">About<span class="flex justify-center" style="align-items:center"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="m13 3 3.293 3.293-7 7 1.414 1.414 7-7L21 11V3z"></path><path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"></path></svg></span></a></div><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="lg:hidden" height="25" width="25" xmlns="http://www.w3.org/2000/svg"><path d="M32 96v64h448V96H32zm0 128v64h448v-64H32zm0 128v64h448v-64H32z"></path></svg></nav><main class="dark:bg-[#0d1117] h-screen pb-10"><div class="flex flex-col w-3/5 sm:w-5/6 m-auto pt-20 pb-20 gap-10 dark:bg-[#0d1117] dark:text-[#c9d1d9]"><ul id="scroll-spy" class="sm:hidden p-10 fixed top-50 right-0 h-full w-1/5 text-gray-500 dark:text-[#c9d1d9]"></ul><div class="text-5xl font-bold">Nginx 리버스 프록시 적용하여 Tomcat과 연동하기</div><div class="flex flex-col gap-2"><div class="text-base text-gray-600 dark:text-gray-300">2022-06-03 10:00</div><div class="flex flex-wrap gap-2 dark:text-black sm:m-0"><span class="p-1 pl-3 pr-3 rounded-md bg-indigo-100 hover:bg-indigo-200 cursor-pointer transition ease-in-out duration-200 text-sm">프로젝트</span></div></div><div class="markdown-body" style="font-size:17px"><p>이번 스프린트에서는 Nginx를 설치하고 리버스 프록시를 적용하여 스프링 부트의 내장 톰캣에 연동하는 작업을 하게 되었는데, 이 과정을 글로 남겨 공유하고자 합니다.</p>
<p>웹 서버는 정적 리소스를 처리하고, WAS는 애플리케이션 로직만을 처리하던 과거와 달리, 현재는 둘 다 정적 리소스, 애플리케이션 로직 모두 처리가 가능합니다. 스프링부트는 톰캣을 내장하고 있기 때문에 그동안 별도의 WAS 설정이나 웹 서버를 구축하지 않아도 잘 동작해 왔습니다.</p>
<p>그렇다면 왜 굳이 웹 서버를 WAS 앞단에 설치해주려는 걸까요?</p>
<p>다양한 이유가 있지만 가장 큰 이유는 다음과 같습니다.</p>
<ul>
<li>WAS 과부하 방지 및 오류 화면 제공</li>
<li>로드 밸런싱을 통한 Scale-Out과 무중단 배포</li>
</ul>
<h2>WAS 과부하 방지 및 오류 화면 제공</h2>
<p>WAS만으로 웹 시스템을 구성하는 경우에 WAS가 너무 많은 역할을 담당하게 되고 서버 과부하가 발생할 우려가 있습니다.</p>
<p>또한 가장 비싼 애플리케이션 로직이 정적 리소스 때문에 수행에 어려움을 겪을 수도 있으며 WAS 장애시 오류 화면 노출도 불가능하다는 문제가 있습니다.</p>
<p><img src="https://i.imgur.com/UyIFlXB.jpg" alt="스크린샷 2022-03-29 오전 11.33.32.png" node="[object Object]" style="max-height:450px;max-width:90%"/></p>
<p>이러한 이유에서 웹 서버인 Nginx를 설치하여 정적 리소스는 웹 서버가 처리하고 WAS는 애플리케이션 로직 처리를 전담할 수 있도록 설계하였습니다.</p>
<p>이렇게 하면 정적 리소스만 제공하는 웹 서버는 잘 죽지 않고 WAS는 잘 죽기 때문에 WAS, DB 장애시 웹 서버가 오류화면을 제공하는 것이 가능하게 됩니다.</p>
<h2>로드 밸런싱을 통한 Scale-Out과 무중단 배포</h2>
<p>이용자 수가 증가하고 서비스의 규모가 커지면 기존의 서버만으로는 트래픽을 감당하는 게 불가능하게 되고, 두 가지 방법을 통해서 트래픽 문제를 해결하게 됩니다.</p>
<ol>
<li>Scale-Up: 기존 서버의 성능을 확장하는 방식</li>
<li>Scale-Out: 기존의 서버와 동일하거나 낮은 성능의 서버를 여러대 증설하는 방식</li>
</ol>
<p>만약 <strong>Scale-Out 방식</strong>으로 서버를 증설하였다면 트래픽을 균등하게 분배해주기 위한 <code node="[object Object]">로드 밸런싱</code> 기법이 필요한데, 웹 서버가 바로 이 로드 밸런싱을 수행하고 여러 WAS에 트래픽을 균등하게 분배해주는 역할을 하게 됩니다. (다양한 로드 밸런싱 알고리즘이 궁금하다면 다음 <a href="https://tecoble.techcourse.co.kr/post/2021-11-07-load-balancing/">링크</a>를 참고해주세요)</p>
<p>웹 서버를 로드밸런서로 사용하면 운영 중인 서비스를 중단하지 않고 신규 소프트웨어를 배포하는 <strong>무중단 배포</strong>가 가능합니다.</p>
<p>무중단 배포 기법에는 <strong>Rolling, Blue-Green, Canary</strong> 등이 있는데  <code node="[object Object]">Blue-Green</code> 배포 방식의 경우, 운영 환경에 구버전과 신버전의 WAS 인스턴스를 구성한 후, 로드밸런서를 통해 신버전으로 모든 트래픽을 전환하는 배포 방식입니다.</p>
<p><img src="https://i.imgur.com/nJo3mSB.png" alt="스크린샷 2022-09-25 오후 1.35.58.png" node="[object Object]" style="max-height:450px;max-width:90%"/>
<!-- -->&lt;small&gt;<!-- -->이미지 출처: <a href="https://www.samsungsds.com/kr/insights/1256264_4627.html">https://www.samsungsds.com/kr/insights/1256264_4627.html</a>&lt;/small&gt;</p>
<p>Blue-Green 배포 방식의 장단점에 대해 간략하게 알아보자면 다음과 같습니다.</p>
<ul>
<li><strong>장점</strong>
<ul>
<li>실제 서비스 환경에서 신버전을 미리 테스트 할 수 있다</li>
<li>빠른 롤백이 가능하다</li>
<li>배포 후 남아 있는 기존 버전의 환경을 다음 배포에 재사용 할 수 있다.</li>
</ul>
</li>
<li><strong>단점</strong>
<ul>
<li>시스템 자원이 두 배로 필요하다</li>
<li>새로운 환경에 대한 테스트가 전제되어야 한다.</li>
</ul>
</li>
</ul>
<h2>웹 서버를 사용한다면 Nginx? Apache?</h2>
<p>위와 같은 이유에서 웹 서버를 설치하기로 결정하였고 어떤 웹 서버를 사용하는 게 프로젝트에 적합할지 고민 이되었습니다. 이를 위해 각각의 웹 서버의 탄생 배경과 장단점에 대해서 알아보았습니다.</p>
<h2>1. Apache</h2>
<p>아파치 서버는 요청이 들어오면 커넥션 형성을 위해서 프로세스를 생성합니다.</p>
<p>따라서 새로운 클라이언트의 요청이 들어올 때 마다 새로운 프로세스를 생성하게 됩니다.</p>
<p>프로세스를 만드는 데는 상당한 비용과 시간이 필요하기 때문에 요청이 들어오기 전에 정해진 수의 프로세스를 미리 만들어 놓는 <code node="[object Object]">PreFork</code> 방식을 사용합니다.</p>
<p>새로운 요청이 들어오면 미리 만들어놓은 프로세스를 할당해주고, 더 이상 할당할 프로세스가 없다면 추가로 프로세스를 만들어서 사용하게 됩니다.</p>
<p>이러한 아파치의 구조 덕분에 <strong>확장성이 좋으며</strong> 다양한 모듈을 만들어서 서버에 빠르게 기능을 추가하는 것이 가능했습니다. 그뿐만 아니라 요청받고, 응답을 처리하는 과정을 <strong>하나의 서버에서</strong> 해결할 수 있게 되었습니다.</p>
<p>하지만 스마트폰이 보급되고 서버에 동시 커넥션 수가 많아지게 되면 서버가 더 이상 커넥션을 생성하지 못하는 문제가 있습니다.</p>
<p>이를 <code node="[object Object]">C10K</code> 문제라고 부릅니다.</p>
<h3>1- 1. <strong>Apache의 문제점 - 동시 커넥션을 처리하기엔 부적합 하다.</strong></h3>
<p>동시 커넥션 수가 많아지면 프로세스 생성 수가 많아지고 이는 곧 메모리 부족 문제로 이어지게 됩니다.</p>
<p>게다가 여러 기능을 쉽게 추가할 수 있다는 확장성 때문에 프로세스가 차지할 리소스의 양도 많아집니다.</p>
<p>많은 커넥션에서 요청이 들어오기 시작하면, CPU는 컨텍스트 스위칭을 해가며 프로세스마다 요청을 처리해야 하므로 CPU에 부하가 발생하게 됩니다.</p>
<h2>2. Nginx</h2>
<p>앞서 언급한 Apache 서버의 구조적 한계를 극복하고자 등장한 게 바로 <code node="[object Object]">Nginx</code> 입니다.</p>
<p>Nginx의 master 프로세스는 설정 파일을 읽고, 설정에 맞게 worker 프로세스를 생성합니다.</p>
<p>worker 프로세스는 만들어지면서 listen socket을 배정받으며, 해당 socket에 새로운 사용자로부터 요청이 들어오면, 커넥션을 형성하고 요청을 처리합니다.</p>
<p>커넥션은 헤더에 지정된 keep-alive 시간만큼 유지됩니다. 하나의 worker 프로세스는 형성된 커넥션에 아무런 요청이 없으면 새로운 커넥션을 형성하거나 이미 만들어진 다른 커넥션으로 부터 요청을 처리합니다. 이러한 커넥션 관련된 작업을 <code node="[object Object]">Event</code> 라고 합니다.</p>
<h2>2-1. Nginx의 Event 기반 구조</h2>
<p>이 Event 들은 OS 커널이 queue 형식으로 worker 프로세스에 전달해 줍니다. Event는 큐에 담긴 상태에서 worker process가 처리할 때까지 비동기 방식으로 대기합니다. worker 프로세스는 하나의 쓰레드로 이벤트를 꺼내서 처리해 나갑니다.</p>
<p>만약 이벤트중 하나가 Disk I/O 와 같이 오래 걸리는 작업일 경우에는 뒤의 요청들이 Blocking 되는 걸 방지하고자 <code node="[object Object]">Thread Pool</code> 이라는 별도의 공간에서 오래 걸리는 작업을 처리합니다.</p>
<p>즉, worker 프로세스는 수행하던 작업이 오래 걸릴것 같으면 해당 작업을 Thread Pool에 위임하고 큐안의 다른 이벤트를 처리하게 됩니다.</p>
<p>이러한 worker 프로세스는 보통 CPU의 코어 개수만큼 생성되는데, 이 덕분에 CPU의 컨텍스트 스위칭 비용을 줄일 수 있으며, 요청이 없다면 프로세스를 방치하던 아파치와 달리, worker 프로세스가 쉬지 않고 일을 하기 때문에 서버 자원을 효율적으로 사용할 수 있게 됩니다.</p>
<p>이처럼 수많은 동시 커넥션을 빠르게 처리하면서 프로세스는 적게 생산하기 때문에 가볍기 까지 한 장점이 있습니다.</p>
<h2>2-2. Nginx의 로드 밸런서 역할</h2>
<p>프로세스를 적게 만들기 때문에 nginx의 설정을 동적으로 변경하는 것이 가능합니다.</p>
<p>개발자가 설정 파일을 변경하고, nginx의 설정 파일을 적용하면 master 프로세스는 해당 설정에 맞는 worker 프로세스를 새로 생성합니다. 그리고 기존에 있던 worker 프로세스가 더 이상 커넥션을 생성하지 않도록 합니다. 기존 worker 프로세스가 담당하던 이벤트 처리가 끝나면 해당 프로세스를 종료하게 됩니다.</p>
<p>이러한 동적 설정 변경은 nginx 뒷단에 새로운 서버를 추가해야 하더라도 nginx를 종료할 필요가 없게 됩니다. 기존 요청은 계속해서 기존 worker 프로세스가 처리하면서, 뒷단에 서버를 추가하는 게 가능하기 때문입니다.</p>
<h2>Reverse Proxy란?</h2>
<p>웹 서버의 역할 중 하나는 WAS에 요청을 보내는 것이며 이를 <strong>리버스 프록시</strong>라고 합니다.</p>
<p>클라이언트는 가짜(proxy) 서버에 요청하면, 프록시 서버가 배후(reverse server)로부터 데이터를 가져오는 역할을 합니다. 여기서 proxy가 nginx이고 reverse server가 WAS를 의미합니다.</p>
<p>nginx.conf 파일의 location 지시어를 사용하여 요청을 배분합니다.</p>
<h2>SSL 터미네이션</h2>
<p>nginx가 클라이언트와는 https 통신을 하고 서버와는 http 통신을 하는 것을 말합니다.</p>
<p>서버는 복호화 과정을 담당할 필요가 없어지기 때문에 비즈니스 로직 처리에 리소스를 더 할당할 수 있게 됩니다. 보통의 nginx와 서버는 같은 네트워크 안에 존재하기 때문에 http 통신을 하더라도 보안 위험이 비교적 적습니다.</p>
<p>이 외에도 nginx를 사용하여 CORS 처리, HSTS, TCP/UDP 커넥션 부하 분산 등의 이점을 얻을 수 있습니다.</p>
<p>Nginx의 동시 커넥션 처리 이점이 현재 진행 중인 프로젝트에 더 적합하다고 느껴졌기 때문에 Nginx를 프로젝트에 적용하기로 하였습니다.</p>
<p>Nginx를 서버 내에 설치하는 과정을 다음과 같이 진행하였습니다.</p>
<h2>ssh연결 통한 Nginx 설치</h2>
<p>OS : Ubuntu 18.04</p>
<h3>설치</h3>
<ul>
<li>nginx 설치<!-- -->
<ul>
<li><code node="[object Object]">sudo apt-get install nginx</code></li>
</ul>
</li>
<li>nginx 설치(버전) 확인<!-- -->
<ul>
<li><code node="[object Object]">nginx -v</code></li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/gef0g1z.png" alt="스크린샷 2022-04-14 오전 1.16.49.png" node="[object Object]" style="max-height:450px;max-width:90%"/></p>
<p>nginx -v를 했을때 버전 정보가 출력된다면 성공적으로 설치된것입니다.</p>
<p>우리는 apt-get을 이용한 패키지 설치를 하였기 때문에 nginx가 <code node="[object Object]">/etc/nginx</code> 폴더에 설치되었습니다.</p>
<p>(직접 compile한 경우에는 <code node="[object Object]">/usr/local/nginx/conf</code> 또는 <code node="[object Object]">/usr/local/etc/nginx</code>에 설치됩니다.</p>
<h3>80 port → WAS</h3>
<p>80번 포트로 들어온 요청을 톰캣 서버로 리버스 프록시하도록 설정하였습니다.</p>
<ul>
<li><code node="[object Object]">vim /etc/nginx/sites-enabled/default</code></li>
</ul>
<p><img src="https://i.imgur.com/Uq0P668.png" alt="스크린샷 2022-06-03 오후 9.10.28.png" node="[object Object]" style="max-height:450px;max-width:90%"/></p>
<pre><div node="[object Object]" style="display:block;overflow-x:auto;padding:0.5em;color:#383a42;background:#fafafa"><code class="language-bash" style="white-space:pre"><span>upstream &lt;업스트림 이름&gt; {
</span>	    &lt;로드밸런싱 알고리즘. 디폴트는 RoundRobin&gt;;
<!-- -->	    server &lt;host1&gt;:&lt;port1&gt;;
<!-- -->	    ...
<!-- -->	    server&lt;hostN&gt;:&lt;portN&gt;;
<!-- -->}</code></div></pre>
<p>“upstream”의 사전적 의미를 살펴보면 강의 상류를 의미합니다. 강의 상류에서 여러 하류로 물을 이동시켜 주는 특징이 nginx가 여러 서버에 분배하는 것과 비슷하기 때문에 <strong>nginx를 upstream 서버</strong>라고 부릅니다.</p>
<p>로드밸런서는 사용자 요청(Load)를 여러 서버로 분배하는데 분배 방법에 따라 여러 기법이 존재합니다.</p>
<p>로드밸런싱 알고리즘으로 아무것도 적지 않으면 기본값인 <code node="[object Object]">RoundRobin</code>으로 동작하게 되는데, <code node="[object Object]">ip_hash</code> 방식으로 요청을 분배하도록 설정하였습니다.</p>
<p><strong>ip_hash 방식</strong>을 사용하면 ip를 해시값으로 해서 요청을 분배하게 되며 한번 접속했던 ip는 계속 같은 서버를 사용하게 됩니다.</p>
<p>현재 저희는 한대의 WAS만을 사용하고 있기 때문에 클라이언트의 요청이 같은 ip 주소로 들어가는걸 보장 하도록 ip_hash 방식을 사용하였으며 아래에는 하나의 WAS ip주소와 포트 번호를 입력해주었습니다.</p>
<pre><div node="[object Object]" style="display:block;overflow-x:auto;padding:0.5em;color:#383a42;background:#fafafa"><code class="language-bash" style="white-space:pre"><span>server {
</span>	...
<!-- -->	server_name &lt;도메인&gt;
<!-- -->	location &lt;url&gt; {
<!-- -->		proxy_pass http://&lt;업스트림 이름&gt;
<!-- -->	}
<!-- -->  	...
<!-- -->}</code></div></pre>
<p>서버의 location에서 로드 밸런싱할 url을 root로 설정하고 proxy_pass에 앞서 작성한 업스트림을 붙혀주었습니다.</p>
<ul>
<li><code node="[object Object]">server_name</code>
<ul>
<li>리버스 프록시를 적용하고자 하는 도메인을 입력해 줍니다. ex) naver.com</li>
</ul>
</li>
<li><code node="[object Object]">location</code>
<ul>
<li>root(/)로 요청이 들어오면 지정해놓은 tomcat 8080포트로 요청을 넘겨줍니다.</li>
</ul>
</li>
</ul>
<h3>Nginx 실행</h3>
<ul>
<li>/ root 경로로 가서<!-- -->
<ul>
<li><code node="[object Object]">systemctl start nginx</code></li>
</ul>
</li>
<li>Nginx 실행 확인<!-- -->
<ul>
<li><code node="[object Object]">systemctl status nginx</code></li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/SFRaNWO.png" alt="스크린샷 2022-04-14 오전 2.11.12.png" node="[object Object]" style="max-height:450px;max-width:90%"/></p>
<p>웹 브라우저에 도메인 IP 주소를 입력하면 톰캣에 잘 연동된것을 확인할 수 있습니다.</p>
<h2>마치며</h2>
<p>지금까지 프로젝트에 웹 서버를 도입한 이유와 Nginx를 선택한 이유, 그리고 설치 과정에 대해서 알아보았습니다.</p>
<p>아직 사용하는 WAS가 한대이기 때문에 로드 밸런싱과 무중단 배포를 적용하지는 않았지만, 프로젝트가 좀 더 진행되면 Nginx를 이용한 로드 밸런싱과 무중단 배포까지의 과정을 정리한 포스트로 돌아오도록 하겠습니다.</p>
<hr/>
<h3>참고 자료 📚</h3>
<p><a href="https://jjeongil.tistory.com/1490">https://jjeongil.tistory.com/1490</a></p>
<p><a href="https://whatisthenext.tistory.com/123">https://whatisthenext.tistory.com/123</a></p>
<p><a href="https://velog.io/@banjjoknim/%EB%A6%AC%EB%B2%84%EC%8A%A4-%ED%94%84%EB%A1%9D%EC%8B%9C">https://velog.io/@banjjoknim/리버스-프록시</a></p>
<p><a href="https://kamang-it.tistory.com/entry/WebServernginxnginx%EB%A1%9C-%EB%A1%9C%EB%93%9C%EB%B0%B8%EB%9F%B0%EC%8B%B1-%ED%95%98%EA%B8%B0">https://kamang-it.tistory.com/entry/WebServernginxnginx로-로드밸런싱-하기</a></p></div><section></section></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"postData":{"id":"promisor-diary3","title":"Nginx 리버스 프록시 적용하여 Tomcat과 연동하기","category":null,"thumbnail":"https://sysopszone.files.wordpress.com/2017/09/loadbalancer.jpeg?w=676","tags":"프로젝트","date":"2022-06-03 10:00","preview":"\n이번 스프린트에서는 Nginx를 설치하고 리버스 프록시를 적용하여 스프링 부트의 내장 톰캣에 연동하는 작업을 하게 되었는데, 이 과정을 글로 남겨 공유하고자 합니다.\n\n웹 서버는 정적 리소스를 처리하고, WAS는 애플리케이션 로직만을 처리하던 과거와"},"detail":"\n이번 스프린트에서는 Nginx를 설치하고 리버스 프록시를 적용하여 스프링 부트의 내장 톰캣에 연동하는 작업을 하게 되었는데, 이 과정을 글로 남겨 공유하고자 합니다.\n\n웹 서버는 정적 리소스를 처리하고, WAS는 애플리케이션 로직만을 처리하던 과거와 달리, 현재는 둘 다 정적 리소스, 애플리케이션 로직 모두 처리가 가능합니다. 스프링부트는 톰캣을 내장하고 있기 때문에 그동안 별도의 WAS 설정이나 웹 서버를 구축하지 않아도 잘 동작해 왔습니다.\n\n그렇다면 왜 굳이 웹 서버를 WAS 앞단에 설치해주려는 걸까요?\n\n다양한 이유가 있지만 가장 큰 이유는 다음과 같습니다.\n\n- WAS 과부하 방지 및 오류 화면 제공\n- 로드 밸런싱을 통한 Scale-Out과 무중단 배포\n\n## WAS 과부하 방지 및 오류 화면 제공\n\nWAS만으로 웹 시스템을 구성하는 경우에 WAS가 너무 많은 역할을 담당하게 되고 서버 과부하가 발생할 우려가 있습니다.\n\n또한 가장 비싼 애플리케이션 로직이 정적 리소스 때문에 수행에 어려움을 겪을 수도 있으며 WAS 장애시 오류 화면 노출도 불가능하다는 문제가 있습니다.\n\n![스크린샷 2022-03-29 오전 11.33.32.png](https://i.imgur.com/UyIFlXB.jpg)\n\n이러한 이유에서 웹 서버인 Nginx를 설치하여 정적 리소스는 웹 서버가 처리하고 WAS는 애플리케이션 로직 처리를 전담할 수 있도록 설계하였습니다.\n\n이렇게 하면 정적 리소스만 제공하는 웹 서버는 잘 죽지 않고 WAS는 잘 죽기 때문에 WAS, DB 장애시 웹 서버가 오류화면을 제공하는 것이 가능하게 됩니다.\n\n## 로드 밸런싱을 통한 Scale-Out과 무중단 배포\n\n이용자 수가 증가하고 서비스의 규모가 커지면 기존의 서버만으로는 트래픽을 감당하는 게 불가능하게 되고, 두 가지 방법을 통해서 트래픽 문제를 해결하게 됩니다.\n\n1. Scale-Up: 기존 서버의 성능을 확장하는 방식\n2. Scale-Out: 기존의 서버와 동일하거나 낮은 성능의 서버를 여러대 증설하는 방식\n\n만약 **Scale-Out 방식**으로 서버를 증설하였다면 트래픽을 균등하게 분배해주기 위한 `로드 밸런싱` 기법이 필요한데, 웹 서버가 바로 이 로드 밸런싱을 수행하고 여러 WAS에 트래픽을 균등하게 분배해주는 역할을 하게 됩니다. (다양한 로드 밸런싱 알고리즘이 궁금하다면 다음 [링크](https://tecoble.techcourse.co.kr/post/2021-11-07-load-balancing/)를 참고해주세요)\n\n웹 서버를 로드밸런서로 사용하면 운영 중인 서비스를 중단하지 않고 신규 소프트웨어를 배포하는 **무중단 배포**가 가능합니다.\n\n무중단 배포 기법에는 **Rolling, Blue-Green, Canary** 등이 있는데  `Blue-Green` 배포 방식의 경우, 운영 환경에 구버전과 신버전의 WAS 인스턴스를 구성한 후, 로드밸런서를 통해 신버전으로 모든 트래픽을 전환하는 배포 방식입니다.\n\n![스크린샷 2022-09-25 오후 1.35.58.png](https://i.imgur.com/nJo3mSB.png)\n\u003csmall\u003e이미지 출처: [https://www.samsungsds.com/kr/insights/1256264_4627.html](https://www.samsungsds.com/kr/insights/1256264_4627.html)\u003c/small\u003e\n\nBlue-Green 배포 방식의 장단점에 대해 간략하게 알아보자면 다음과 같습니다.\n\n- **장점**\n    - 실제 서비스 환경에서 신버전을 미리 테스트 할 수 있다\n    - 빠른 롤백이 가능하다\n    - 배포 후 남아 있는 기존 버전의 환경을 다음 배포에 재사용 할 수 있다.\n- **단점**\n    - 시스템 자원이 두 배로 필요하다\n    - 새로운 환경에 대한 테스트가 전제되어야 한다.\n\n## 웹 서버를 사용한다면 Nginx? Apache?\n\n위와 같은 이유에서 웹 서버를 설치하기로 결정하였고 어떤 웹 서버를 사용하는 게 프로젝트에 적합할지 고민 이되었습니다. 이를 위해 각각의 웹 서버의 탄생 배경과 장단점에 대해서 알아보았습니다.\n\n## 1. Apache\n\n아파치 서버는 요청이 들어오면 커넥션 형성을 위해서 프로세스를 생성합니다.\n\n따라서 새로운 클라이언트의 요청이 들어올 때 마다 새로운 프로세스를 생성하게 됩니다.\n\n프로세스를 만드는 데는 상당한 비용과 시간이 필요하기 때문에 요청이 들어오기 전에 정해진 수의 프로세스를 미리 만들어 놓는 `PreFork` 방식을 사용합니다.\n\n새로운 요청이 들어오면 미리 만들어놓은 프로세스를 할당해주고, 더 이상 할당할 프로세스가 없다면 추가로 프로세스를 만들어서 사용하게 됩니다.\n\n이러한 아파치의 구조 덕분에 **확장성이 좋으며** 다양한 모듈을 만들어서 서버에 빠르게 기능을 추가하는 것이 가능했습니다. 그뿐만 아니라 요청받고, 응답을 처리하는 과정을 **하나의 서버에서** 해결할 수 있게 되었습니다.\n\n하지만 스마트폰이 보급되고 서버에 동시 커넥션 수가 많아지게 되면 서버가 더 이상 커넥션을 생성하지 못하는 문제가 있습니다.\n\n이를 `C10K` 문제라고 부릅니다.\n\n### 1- 1. **Apache의 문제점 - 동시 커넥션을 처리하기엔 부적합 하다.**\n\n동시 커넥션 수가 많아지면 프로세스 생성 수가 많아지고 이는 곧 메모리 부족 문제로 이어지게 됩니다.\n\n게다가 여러 기능을 쉽게 추가할 수 있다는 확장성 때문에 프로세스가 차지할 리소스의 양도 많아집니다.\n\n많은 커넥션에서 요청이 들어오기 시작하면, CPU는 컨텍스트 스위칭을 해가며 프로세스마다 요청을 처리해야 하므로 CPU에 부하가 발생하게 됩니다.\n\n## 2. Nginx\n\n앞서 언급한 Apache 서버의 구조적 한계를 극복하고자 등장한 게 바로 `Nginx` 입니다.\n\nNginx의 master 프로세스는 설정 파일을 읽고, 설정에 맞게 worker 프로세스를 생성합니다.\n\nworker 프로세스는 만들어지면서 listen socket을 배정받으며, 해당 socket에 새로운 사용자로부터 요청이 들어오면, 커넥션을 형성하고 요청을 처리합니다.\n\n커넥션은 헤더에 지정된 keep-alive 시간만큼 유지됩니다. 하나의 worker 프로세스는 형성된 커넥션에 아무런 요청이 없으면 새로운 커넥션을 형성하거나 이미 만들어진 다른 커넥션으로 부터 요청을 처리합니다. 이러한 커넥션 관련된 작업을 `Event` 라고 합니다.\n\n## 2-1. Nginx의 Event 기반 구조\n\n이 Event 들은 OS 커널이 queue 형식으로 worker 프로세스에 전달해 줍니다. Event는 큐에 담긴 상태에서 worker process가 처리할 때까지 비동기 방식으로 대기합니다. worker 프로세스는 하나의 쓰레드로 이벤트를 꺼내서 처리해 나갑니다.\n\n만약 이벤트중 하나가 Disk I/O 와 같이 오래 걸리는 작업일 경우에는 뒤의 요청들이 Blocking 되는 걸 방지하고자 `Thread Pool` 이라는 별도의 공간에서 오래 걸리는 작업을 처리합니다.\n\n즉, worker 프로세스는 수행하던 작업이 오래 걸릴것 같으면 해당 작업을 Thread Pool에 위임하고 큐안의 다른 이벤트를 처리하게 됩니다.\n\n이러한 worker 프로세스는 보통 CPU의 코어 개수만큼 생성되는데, 이 덕분에 CPU의 컨텍스트 스위칭 비용을 줄일 수 있으며, 요청이 없다면 프로세스를 방치하던 아파치와 달리, worker 프로세스가 쉬지 않고 일을 하기 때문에 서버 자원을 효율적으로 사용할 수 있게 됩니다.\n\n이처럼 수많은 동시 커넥션을 빠르게 처리하면서 프로세스는 적게 생산하기 때문에 가볍기 까지 한 장점이 있습니다.\n\n## 2-2. Nginx의 로드 밸런서 역할\n\n프로세스를 적게 만들기 때문에 nginx의 설정을 동적으로 변경하는 것이 가능합니다.\n\n개발자가 설정 파일을 변경하고, nginx의 설정 파일을 적용하면 master 프로세스는 해당 설정에 맞는 worker 프로세스를 새로 생성합니다. 그리고 기존에 있던 worker 프로세스가 더 이상 커넥션을 생성하지 않도록 합니다. 기존 worker 프로세스가 담당하던 이벤트 처리가 끝나면 해당 프로세스를 종료하게 됩니다.\n\n이러한 동적 설정 변경은 nginx 뒷단에 새로운 서버를 추가해야 하더라도 nginx를 종료할 필요가 없게 됩니다. 기존 요청은 계속해서 기존 worker 프로세스가 처리하면서, 뒷단에 서버를 추가하는 게 가능하기 때문입니다.\n\n## Reverse Proxy란?\n\n웹 서버의 역할 중 하나는 WAS에 요청을 보내는 것이며 이를 **리버스 프록시**라고 합니다.\n\n클라이언트는 가짜(proxy) 서버에 요청하면, 프록시 서버가 배후(reverse server)로부터 데이터를 가져오는 역할을 합니다. 여기서 proxy가 nginx이고 reverse server가 WAS를 의미합니다.\n\nnginx.conf 파일의 location 지시어를 사용하여 요청을 배분합니다.\n\n## SSL 터미네이션\n\nnginx가 클라이언트와는 https 통신을 하고 서버와는 http 통신을 하는 것을 말합니다.\n\n서버는 복호화 과정을 담당할 필요가 없어지기 때문에 비즈니스 로직 처리에 리소스를 더 할당할 수 있게 됩니다. 보통의 nginx와 서버는 같은 네트워크 안에 존재하기 때문에 http 통신을 하더라도 보안 위험이 비교적 적습니다.\n\n이 외에도 nginx를 사용하여 CORS 처리, HSTS, TCP/UDP 커넥션 부하 분산 등의 이점을 얻을 수 있습니다.\n\nNginx의 동시 커넥션 처리 이점이 현재 진행 중인 프로젝트에 더 적합하다고 느껴졌기 때문에 Nginx를 프로젝트에 적용하기로 하였습니다.\n\nNginx를 서버 내에 설치하는 과정을 다음과 같이 진행하였습니다.\n\n## ssh연결 통한 Nginx 설치\n\nOS : Ubuntu 18.04\n\n### 설치\n\n- nginx 설치\n    - `sudo apt-get install nginx`\n- nginx 설치(버전) 확인\n    - `nginx -v`\n\n![스크린샷 2022-04-14 오전 1.16.49.png](https://i.imgur.com/gef0g1z.png)\n\nnginx -v를 했을때 버전 정보가 출력된다면 성공적으로 설치된것입니다.\n\n우리는 apt-get을 이용한 패키지 설치를 하였기 때문에 nginx가 `/etc/nginx` 폴더에 설치되었습니다.\n\n(직접 compile한 경우에는 `/usr/local/nginx/conf` 또는 `/usr/local/etc/nginx`에 설치됩니다.\n\n\n\n### 80 port → WAS\n\n80번 포트로 들어온 요청을 톰캣 서버로 리버스 프록시하도록 설정하였습니다.\n\n- `vim /etc/nginx/sites-enabled/default`\n\n![스크린샷 2022-06-03 오후 9.10.28.png](https://i.imgur.com/Uq0P668.png)\n\n```bash\nupstream \u003c업스트림 이름\u003e {\n\t    \u003c로드밸런싱 알고리즘. 디폴트는 RoundRobin\u003e;\n\t    server \u003chost1\u003e:\u003cport1\u003e;\n\t    ...\n\t    server\u003chostN\u003e:\u003cportN\u003e;\n}\n```\n\n“upstream”의 사전적 의미를 살펴보면 강의 상류를 의미합니다. 강의 상류에서 여러 하류로 물을 이동시켜 주는 특징이 nginx가 여러 서버에 분배하는 것과 비슷하기 때문에 **nginx를 upstream 서버**라고 부릅니다.\n\n로드밸런서는 사용자 요청(Load)를 여러 서버로 분배하는데 분배 방법에 따라 여러 기법이 존재합니다.\n\n로드밸런싱 알고리즘으로 아무것도 적지 않으면 기본값인 `RoundRobin`으로 동작하게 되는데, `ip_hash` 방식으로 요청을 분배하도록 설정하였습니다.\n\n**ip_hash 방식**을 사용하면 ip를 해시값으로 해서 요청을 분배하게 되며 한번 접속했던 ip는 계속 같은 서버를 사용하게 됩니다.\n\n현재 저희는 한대의 WAS만을 사용하고 있기 때문에 클라이언트의 요청이 같은 ip 주소로 들어가는걸 보장 하도록 ip_hash 방식을 사용하였으며 아래에는 하나의 WAS ip주소와 포트 번호를 입력해주었습니다.\n\n```bash\nserver {\n\t...\n\tserver_name \u003c도메인\u003e\n\tlocation \u003curl\u003e {\n\t\tproxy_pass http://\u003c업스트림 이름\u003e\n\t}\n  \t...\n}\n```\n\n서버의 location에서 로드 밸런싱할 url을 root로 설정하고 proxy_pass에 앞서 작성한 업스트림을 붙혀주었습니다.\n\n- `server_name`\n    - 리버스 프록시를 적용하고자 하는 도메인을 입력해 줍니다. ex) naver.com\n- `location`\n    - root(/)로 요청이 들어오면 지정해놓은 tomcat 8080포트로 요청을 넘겨줍니다.\n\n### Nginx 실행\n\n- / root 경로로 가서\n    - `systemctl start nginx`\n- Nginx 실행 확인\n    - `systemctl status nginx`\n\n![스크린샷 2022-04-14 오전 2.11.12.png](https://i.imgur.com/SFRaNWO.png)\n\n웹 브라우저에 도메인 IP 주소를 입력하면 톰캣에 잘 연동된것을 확인할 수 있습니다.\n\n## 마치며\n\n지금까지 프로젝트에 웹 서버를 도입한 이유와 Nginx를 선택한 이유, 그리고 설치 과정에 대해서 알아보았습니다.\n\n아직 사용하는 WAS가 한대이기 때문에 로드 밸런싱과 무중단 배포를 적용하지는 않았지만, 프로젝트가 좀 더 진행되면 Nginx를 이용한 로드 밸런싱과 무중단 배포까지의 과정을 정리한 포스트로 돌아오도록 하겠습니다.\n\n---\n\n### 참고 자료 📚\n\n[https://jjeongil.tistory.com/1490](https://jjeongil.tistory.com/1490)\n\n[https://whatisthenext.tistory.com/123](https://whatisthenext.tistory.com/123)\n\n[https://velog.io/@banjjoknim/리버스-프록시](https://velog.io/@banjjoknim/%EB%A6%AC%EB%B2%84%EC%8A%A4-%ED%94%84%EB%A1%9D%EC%8B%9C)\n\n[https://kamang-it.tistory.com/entry/WebServernginxnginx로-로드밸런싱-하기](https://kamang-it.tistory.com/entry/WebServernginxnginx%EB%A1%9C-%EB%A1%9C%EB%93%9C%EB%B0%B8%EB%9F%B0%EC%8B%B1-%ED%95%98%EA%B8%B0)\n"},"__N_SSG":true},"page":"/[id]","query":{"id":"promisor-diary3"},"buildId":"DgHcyLVbQaP3fKIpTojx6","assetPrefix":"/TIL","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>